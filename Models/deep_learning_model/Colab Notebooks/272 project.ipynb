{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"272 project.ipynb","version":"0.3.2","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"sK-OQ1fsitew","colab_type":"code","outputId":"6825408f-7a80-4db4-c2ca-098c161be31e","executionInfo":{"status":"ok","timestamp":1553270188542,"user_tz":240,"elapsed":105126,"user":{"displayName":"Yue Wang","photoUrl":"","userId":"12597940806287112734"}},"colab":{"base_uri":"https://localhost:8080/","height":3404}},"cell_type":"code","source":["!pip install allennlp"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting allennlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/32/d6d0a93a23763f366df2dbd4e007e45ce4d2ad97e6315506db9da8af7731/allennlp-0.8.2-py3-none-any.whl (5.6MB)\n","\u001b[K    100% |████████████████████████████████| 5.6MB 4.3MB/s \n","\u001b[?25hCollecting sqlparse==0.2.4 (from allennlp)\n","  Downloading https://files.pythonhosted.org/packages/65/85/20bdd72f4537cf2c4d5d005368d502b2f464ede22982e724a82c86268eda/sqlparse-0.2.4-py2.py3-none-any.whl\n","Collecting conllu==0.11 (from allennlp)\n","  Downloading https://files.pythonhosted.org/packages/d4/2c/856344d9b69baf5b374c395b4286626181a80f0c2b2f704914d18a1cea47/conllu-0.11-py2.py3-none-any.whl\n","Collecting moto==1.3.4 (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/8f/7b36e81ff067d0e7bf90f7210b351c0cfe6657f79fa4dcb0cb4787462e05/moto-1.3.4-py2.py3-none-any.whl (548kB)\n","\u001b[K    100% |████████████████████████████████| 552kB 17.3MB/s \n","\u001b[?25hCollecting parsimonious==0.8.0 (from allennlp)\n","  Downloading https://files.pythonhosted.org/packages/4a/89/32c55944cd30dff856f16859ee325b13c83c260d0c56c0eed511e8063c87/parsimonious-0.8.0.tar.gz\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.0)\n","Requirement already satisfied: flask==1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.0.2)\n","Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.6)\n","Collecting flaky (from allennlp)\n","  Downloading https://files.pythonhosted.org/packages/02/42/cca66659a786567c8af98587d66d75e7d2b6e65662f8daab75db708ac35b/flaky-3.5.3-py2.py3-none-any.whl\n","Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n","Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.28.1)\n","Collecting ftfy (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/86/df789c5834f15ae1ca53a8d4c1fc4788676c2e32112f6a786f2625d9c6e6/ftfy-5.5.1-py3-none-any.whl (43kB)\n","\u001b[K    100% |████████████████████████████████| 51kB 14.4MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.9.115)\n","Collecting gevent==1.3.6 (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/3d/a19fece28ba1b5133cf74bd22a229d77b4d9cc4b24aa8f263cca2845c555/gevent-1.3.6-cp36-cp36m-manylinux1_x86_64.whl (4.5MB)\n","\u001b[K    100% |████████████████████████████████| 4.5MB 6.2MB/s \n","\u001b[?25hCollecting unidecode (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/39/53096f9217b057cb049fe872b7fc7ce799a1a89b76cf917d9639e7a558b5/Unidecode-1.0.23-py2.py3-none-any.whl (237kB)\n","\u001b[K    100% |████████████████████████████████| 245kB 23.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.14.6)\n","Collecting awscli>=1.11.91 (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/68/325a40f6ce680b128faa70b0287f7d4be5e0031b819884b94b7251aa33c6/awscli-1.16.129-py2.py3-none-any.whl (1.5MB)\n","\u001b[K    100% |████████████████████████████████| 1.5MB 13.1MB/s \n","\u001b[?25hCollecting jsonnet==0.10.0; sys_platform != \"win32\" (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/83/d49904ee98dd4fbba6a003938e30e76251951c4bdb49628b4f92e5009a42/jsonnet-0.10.0.tar.gz (124kB)\n","\u001b[K    100% |████████████████████████████████| 133kB 23.9MB/s \n","\u001b[?25hCollecting flask-cors==3.0.7 (from allennlp)\n","  Downloading https://files.pythonhosted.org/packages/65/cb/683f71ff8daa3aea0a5cbb276074de39f9ab66d3fbb8ad5efb5bb83e90d2/Flask_Cors-3.0.7-py2.py3-none-any.whl\n","Collecting numpydoc==0.8.0 (from allennlp)\n","  Downloading https://files.pythonhosted.org/packages/95/a8/b4706a6270f0475541c5c1ee3373c7a3b793936ec1f517f1a1dab4f896c0/numpydoc-0.8.0.tar.gz\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.5)\n","Collecting tensorboardX==1.2 (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/22/43f4f0318f7c68a1000dbb700a353b745584bc2397437832d15ba69ea5f1/tensorboardX-1.2-py2.py3-none-any.whl (44kB)\n","\u001b[K    100% |████████████████████████████████| 51kB 13.5MB/s \n","\u001b[?25hCollecting pytorch-pretrained-bert>=0.6.0 (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/3c/d5fa084dd3a82ffc645aba78c417e6072ff48552e3301b1fa3bd711e03d4/pytorch_pretrained_bert-0.6.1-py3-none-any.whl (114kB)\n","\u001b[K    100% |████████████████████████████████| 122kB 26.9MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.8.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.20.3)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.3)\n","Collecting responses>=0.7 (from allennlp)\n","  Downloading https://files.pythonhosted.org/packages/d1/5a/b887e89925f1de7890ef298a74438371ed4ed29b33def9e6d02dc6036fd8/responses-0.10.6-py2.py3-none-any.whl\n","Collecting matplotlib==2.2.3 (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/59/f235ab21bbe7b7c6570c4abf17ffb893071f4fa3b9cf557b09b60359ad9a/matplotlib-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (12.6MB)\n","\u001b[K    100% |████████████████████████████████| 12.6MB 2.9MB/s \n","\u001b[?25hCollecting pytz==2017.3 (from allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/7f/e7d1acbd433b929168a4fb4182a2ff3c33653717195a26c1de099ad1ef29/pytz-2017.3-py2.py3-none-any.whl (511kB)\n","\u001b[K    100% |████████████████████████████████| 512kB 20.1MB/s \n","\u001b[?25hRequirement already satisfied: spacy<2.1,>=2.0 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.0.18)\n","Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.18.4)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.0.1.post2)\n","Collecting overrides (from allennlp)\n","  Downloading https://files.pythonhosted.org/packages/de/55/3100c6d14c1ed177492fcf8f07c4a7d2d6c996c0a7fc6a9a0a41308e7eec/overrides-1.9.tar.gz\n","Requirement already satisfied: mock in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (2.0.0)\n","Collecting jsondiff==1.1.1 (from moto==1.3.4->allennlp)\n","  Downloading https://files.pythonhosted.org/packages/bd/5f/13e28a2f9abeda2ffb3f44f2f809b01b52bc02cdb63816e05b8c9cbbdfc5/jsondiff-1.1.1.tar.gz\n","Requirement already satisfied: botocore>=1.9.16 in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (1.12.115)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (1.11.0)\n","Collecting aws-xray-sdk<0.96,>=0.93 (from moto==1.3.4->allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/a5/da7887285564f9e0ae5cd25a453cca36e2cd43d8ccc9effde260b4d80904/aws_xray_sdk-0.95-py2.py3-none-any.whl (52kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 16.4MB/s \n","\u001b[?25hCollecting pyaml (from moto==1.3.4->allennlp)\n","  Downloading https://files.pythonhosted.org/packages/c5/e1/1523fb1dab744e2c6b1f02446f2139a78726c18c062a8ddd53875abb20f8/pyaml-18.11.0-py2.py3-none-any.whl\n","Requirement already satisfied: boto>=2.36.0 in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (2.49.0)\n","Collecting xmltodict (from moto==1.3.4->allennlp)\n","  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n","Collecting python-jose<3.0.0 (from moto==1.3.4->allennlp)\n","  Downloading https://files.pythonhosted.org/packages/bf/5c/5fa238c0c5b0656994b52721dd8b1d7bf52ebd8786518dde794f44de86b6/python_jose-2.0.2-py2.py3-none-any.whl\n","Collecting docker>=2.5.1 (from moto==1.3.4->allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/d8/8242b8fb3bd3000274fbf5ac1a06cdba8a5ccbcf4e2a8c05f0ab37999fd8/docker-3.7.1-py2.py3-none-any.whl (134kB)\n","\u001b[K    100% |████████████████████████████████| 143kB 25.3MB/s \n","\u001b[?25hCollecting cookies (from moto==1.3.4->allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/60/557f84aa2db629e5124aa05408b975b1b5d0e1cec16cde0bfa06aae097d3/cookies-2.2.1-py2.py3-none-any.whl (44kB)\n","\u001b[K    100% |████████████████████████████████| 51kB 16.9MB/s \n","\u001b[?25hRequirement already satisfied: werkzeug in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (0.14.1)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (2.5.3)\n","Collecting cryptography>=2.0.0 (from moto==1.3.4->allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/12/b0409a94dad366d98a8eee2a77678c7a73aafd8c0e4b835abea634ea3896/cryptography-2.6.1-cp34-abi3-manylinux1_x86_64.whl (2.3MB)\n","\u001b[K    100% |████████████████████████████████| 2.3MB 8.9MB/s \n","\u001b[?25hRequirement already satisfied: Jinja2>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from moto==1.3.4->allennlp) (2.10)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask==1.0.2->allennlp) (7.0)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask==1.0.2->allennlp) (1.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (40.8.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (6.0.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.3.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.8.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.1.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.1.7)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.9.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.2.0)\n","Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.6/dist-packages (from gevent==1.3.6->allennlp) (0.4.15)\n","Requirement already satisfied: PyYAML<=3.13,>=3.10 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (3.13)\n","Collecting rsa<=3.5.0,>=3.1.2 (from awscli>=1.11.91->allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/ae/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e/rsa-3.4.2-py2.py3-none-any.whl (46kB)\n","\u001b[K    100% |████████████████████████████████| 51kB 14.1MB/s \n","\u001b[?25hCollecting colorama<=0.3.9,>=0.2.5 (from awscli>=1.11.91->allennlp)\n","  Downloading https://files.pythonhosted.org/packages/db/c8/7dcf9dbcb22429512708fe3a547f8b6101c0d02137acbd892505aee57adf/colorama-0.3.9-py2.py3-none-any.whl\n","Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from awscli>=1.11.91->allennlp) (0.14)\n","Requirement already satisfied: sphinx>=1.2.3 in /usr/local/lib/python3.6/dist-packages (from numpydoc==0.8.0->allennlp) (1.8.5)\n","Requirement already satisfied: protobuf>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorboardX==1.2->allennlp) (3.7.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.0->allennlp) (2018.1.10)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.3->allennlp) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.3->allennlp) (2.3.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.3->allennlp) (1.0.1)\n","Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp) (2.0.1)\n","Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp) (1.35)\n","Requirement already satisfied: thinc<6.13.0,>=6.12.1 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp) (6.12.1)\n","Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp) (0.9.6)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp) (2.0.2)\n","Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp) (0.2.9)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.1,>=2.0->allennlp) (1.0.2)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2019.3.9)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.6)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.22)\n","Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock->moto==1.3.4->allennlp) (5.1.3)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from aws-xray-sdk<0.96,>=0.93->moto==1.3.4->allennlp) (1.10.11)\n","Collecting jsonpickle (from aws-xray-sdk<0.96,>=0.93->moto==1.3.4->allennlp)\n","  Downloading https://files.pythonhosted.org/packages/dc/12/8c44eabb501e2bc0aec0dd152b328074d98a50968d3a02be28f6037f0c6a/jsonpickle-1.1-py2.py3-none-any.whl\n","Collecting ecdsa<1.0 (from python-jose<3.0.0->moto==1.3.4->allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/f4/73669d51825516ce8c43b816c0a6b64cd6eb71d08b99820c00792cb42222/ecdsa-0.13-py2.py3-none-any.whl (86kB)\n","\u001b[K    100% |████████████████████████████████| 92kB 20.6MB/s \n","\u001b[?25hCollecting pycryptodome<4.0.0,>=3.3.1 (from python-jose<3.0.0->moto==1.3.4->allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/cf/4b66bf1ac2484ca39599b4576d681186b61b543c2d2c29f9aa4ba3cc53b5/pycryptodome-3.7.3-cp36-cp36m-manylinux1_x86_64.whl (7.5MB)\n","\u001b[K    100% |████████████████████████████████| 7.5MB 4.6MB/s \n","\u001b[?25hRequirement already satisfied: future<1.0 in /usr/local/lib/python3.6/dist-packages (from python-jose<3.0.0->moto==1.3.4->allennlp) (0.16.0)\n","Collecting docker-pycreds>=0.4.0 (from docker>=2.5.1->moto==1.3.4->allennlp)\n","  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Collecting websocket-client>=0.32.0 (from docker>=2.5.1->moto==1.3.4->allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n","\u001b[K    100% |████████████████████████████████| 204kB 25.3MB/s \n","\u001b[?25hCollecting asn1crypto>=0.21.0 (from cryptography>=2.0.0->moto==1.3.4->allennlp)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n","\u001b[K    100% |████████████████████████████████| 102kB 25.0MB/s \n","\u001b[?25hRequirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.0.0->moto==1.3.4->allennlp) (1.12.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7.3->moto==1.3.4->allennlp) (1.1.1)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=3.5.0,>=3.1.2->awscli>=1.11.91->allennlp) (0.4.5)\n","Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (2.6.0)\n","Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (2.1.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (19.0)\n","Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (1.2.1)\n","Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (0.7.12)\n","Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (1.1.0)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.2.3->numpydoc==0.8.0->allennlp) (1.1.0)\n","Requirement already satisfied: msgpack-numpy<0.4.4 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy<2.1,>=2.0->allennlp) (0.4.3.2)\n","Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.13.0,>=6.12.1->spacy<2.1,>=2.0->allennlp) (0.9.0.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.0.0->moto==1.3.4->allennlp) (2.19)\n","Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy<2.1,>=2.0->allennlp) (0.9.0)\n","Building wheels for collected packages: parsimonious, jsonnet, numpydoc, overrides, jsondiff\n","  Building wheel for parsimonious (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/bb/51/82/ae9b22a790f11e7be918939d01aa397c545ebb3723453c5fb4\n","  Building wheel for jsonnet (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a0/aa/f0/b4ab8854cf00f922a87787425cfbb789aac01ab2c2cd1b4ca4\n","  Building wheel for numpydoc (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ea/55/7f/3e25d754760ccd62d6796e5b2cfe25629346f52ea00753d549\n","  Building wheel for overrides (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/8d/52/86/e5a83b1797e7d263b458d2334edd2704c78508b3eea9323718\n","  Building wheel for jsondiff (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/68/08/07/69d839606fb7fdc778fa86476abc0a864693d45969a0c1936c\n","Successfully built parsimonious jsonnet numpydoc overrides jsondiff\n","\u001b[31mimgaug 0.2.8 has requirement numpy>=1.15.0, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n","\u001b[31mfeaturetools 0.4.1 has requirement pandas>=0.23.0, but you'll have pandas 0.22.0 which is incompatible.\u001b[0m\n","\u001b[31mfastai 1.0.49 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n","\u001b[31malbumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n","\u001b[31mawscli 1.16.129 has requirement botocore==1.12.119, but you'll have botocore 1.12.115 which is incompatible.\u001b[0m\n","Installing collected packages: sqlparse, conllu, jsondiff, jsonpickle, aws-xray-sdk, responses, pyaml, xmltodict, pytz, ecdsa, pycryptodome, python-jose, docker-pycreds, websocket-client, docker, cookies, asn1crypto, cryptography, moto, parsimonious, flaky, ftfy, gevent, unidecode, rsa, colorama, awscli, jsonnet, flask-cors, numpydoc, tensorboardX, pytorch-pretrained-bert, matplotlib, overrides, allennlp\n","  Found existing installation: sqlparse 0.3.0\n","    Uninstalling sqlparse-0.3.0:\n","      Successfully uninstalled sqlparse-0.3.0\n","  Found existing installation: pytz 2018.9\n","    Uninstalling pytz-2018.9:\n","      Successfully uninstalled pytz-2018.9\n","  Found existing installation: gevent 1.4.0\n","    Uninstalling gevent-1.4.0:\n","      Successfully uninstalled gevent-1.4.0\n","  Found existing installation: rsa 4.0\n","    Uninstalling rsa-4.0:\n","      Successfully uninstalled rsa-4.0\n","  Found existing installation: matplotlib 3.0.3\n","    Uninstalling matplotlib-3.0.3:\n","      Successfully uninstalled matplotlib-3.0.3\n","Successfully installed allennlp-0.8.2 asn1crypto-0.24.0 aws-xray-sdk-0.95 awscli-1.16.129 colorama-0.3.9 conllu-0.11 cookies-2.2.1 cryptography-2.6.1 docker-3.7.1 docker-pycreds-0.4.0 ecdsa-0.13 flaky-3.5.3 flask-cors-3.0.7 ftfy-5.5.1 gevent-1.3.6 jsondiff-1.1.1 jsonnet-0.10.0 jsonpickle-1.1 matplotlib-2.2.3 moto-1.3.4 numpydoc-0.8.0 overrides-1.9 parsimonious-0.8.0 pyaml-18.11.0 pycryptodome-3.7.3 python-jose-2.0.2 pytorch-pretrained-bert-0.6.1 pytz-2017.3 responses-0.10.6 rsa-3.4.2 sqlparse-0.2.4 tensorboardX-1.2 unidecode-1.0.23 websocket-client-0.56.0 xmltodict-0.12.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["matplotlib","mpl_toolkits","pytz","rsa"]}}},"metadata":{"tags":[]}}]},{"metadata":{"id":"oUQ1pAFEndyN","colab_type":"code","outputId":"2d8c67b1-e617-4059-bddc-206d382a77e4","executionInfo":{"status":"ok","timestamp":1553270336339,"user_tz":240,"elapsed":6349,"user":{"displayName":"Yue Wang","photoUrl":"","userId":"12597940806287112734"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import itertools\n","from allennlp.data.tokenizers import Token\n","from allennlp.data.dataset_readers import DatasetReader\n","from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer, TokenCharactersIndexer\n","from allennlp.data.fields import TextField, LabelField\n","from allennlp.data import Instance\n","from typing import Iterator, List, Dict\n","from allennlp.models import Model\n","from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n","from allennlp.modules.token_embedders import Embedding, TokenCharactersEncoder\n","from allennlp.modules.seq2vec_encoders import Seq2VecEncoder\n","from allennlp.data.vocabulary import Vocabulary\n","from allennlp.nn.util import get_text_field_mask\n","from allennlp.training.metrics import CategoricalAccuracy\n","from allennlp.modules.seq2vec_encoders import PytorchSeq2VecWrapper, BagOfEmbeddingsEncoder\n","from allennlp.data.iterators import BasicIterator\n","from allennlp.training.trainer import Trainer\n","import torch.optim as optim\n","from allennlp.predictors.predictor import Predictor\n","\n","import torch\n","import pickle"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"],"name":"stdout"}]},{"metadata":{"id":"mJc2x436cG19","colab_type":"text"},"cell_type":"markdown","source":["### For AllenNLP to work, usually we need to find two things: data reader and model."]},{"metadata":{"id":"9oVuz0Wlol0d","colab_type":"code","colab":{}},"cell_type":"code","source":["class JobReader(DatasetReader):\n","    def __init__(self, token_indexers: Dict[str, TokenIndexer] = None) -> None:\n","        super().__init__(lazy=False)\n","        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n","        \n","    def text_to_instance(self, tokens: List[Token], tag: int = None) -> Instance:\n","        job_field = TextField(tokens, self.token_indexers)\n","        fields = {\"tokens\": job_field}\n","        \n","        label_field = LabelField(label=str(tag))\n","        fields[\"label\"] = label_field\n","\n","        return Instance(fields)\n","    \n","    def _read(self, file_path: str) -> Iterator[Instance]:\n","        with (open(file_path, \"rb\")) as openfile:\n","            basic = pickle.load(openfile)\n","        for each in basic:\n","            text = [x.strip().split()+['<eos>'] for x in each['text'] if x!='']\n","            words = list(itertools.chain(*text))\n","            yield self.text_to_instance([Token(word) for word in words], each['salary_range'])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RIkm_EE_oob5","colab_type":"code","colab":{}},"cell_type":"code","source":["class LstmClassifier(Model):\n","    def __init__(self,\n","                 word_embeddings: TextFieldEmbedder,\n","                 encoder: Seq2VecEncoder,\n","                 vocab: Vocabulary) -> None:\n","        super().__init__(vocab)\n","        self.word_embeddings = word_embeddings\n","\n","        self.encoder = encoder\n","\n","        self.hidden2tag = torch.nn.Linear(in_features=encoder.get_output_dim(),\n","                                          out_features=vocab.get_vocab_size('labels'))\n","        self.metrics = {\n","            \"accuracy\": CategoricalAccuracy()\n","        }\n","\n","        self.loss_function = torch.nn.CrossEntropyLoss()\n","\n","    def forward(self,\n","                tokens: Dict[str, torch.Tensor],\n","                label: torch.Tensor = None) -> torch.Tensor:\n","        mask = get_text_field_mask(tokens)\n","\n","        embeddings = self.word_embeddings(tokens)\n","        encoder_out = self.encoder(embeddings, mask)\n","        logits = self.hidden2tag(encoder_out)\n","\n","        output = {\"logits\": logits}\n","        if label is not None:\n","            for metric in self.metrics.values():\n","                metric(logits, label)\n","            output[\"loss\"] = self.loss_function(logits, label)\n","\n","        return output\n","    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n","        return {metric_name: metric.get_metric(reset) for metric_name, metric in self.metrics.items()}"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Non39i2PcTHa","colab_type":"text"},"cell_type":"markdown","source":["### To access the data in my Google Drive, I need the following code to attach that path to our working environment."]},{"metadata":{"id":"U3HN4M8mqWhw","colab_type":"code","outputId":"7461a9c4-6734-426e-b3f9-80fbf05c1da0","executionInfo":{"status":"ok","timestamp":1553270369418,"user_tz":240,"elapsed":21591,"user":{"displayName":"Yue Wang","photoUrl":"","userId":"12597940806287112734"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"q0ByCn5sFEp3","colab_type":"code","colab":{}},"cell_type":"code","source":["# import pickle\n","# with open('/content/gdrive/My Drive/2.1_data.pkl', 'rb') as handle:\n","#     d = pickle.load(handle)\n","\n","# import numpy as np\n","# a, b, c = np.split(np.random.permutation(len(d)), [int(0.7*len(d)), int(0.9*len(d))])\n","# with open('/content/gdrive/My Drive/2.1_train.pkl', 'wb') as handle:\n","#     pickle.dump([d[i] for i in a], handle, protocol=pickle.HIGHEST_PROTOCOL)\n","# with open('/content/gdrive/My Drive/2.1_dev.pkl', 'wb') as handle:\n","#     pickle.dump([d[i] for i in b], handle, protocol=pickle.HIGHEST_PROTOCOL)\n","# with open('/content/gdrive/My Drive/2.1_test.pkl', 'wb') as handle:\n","#     pickle.dump([d[i] for i in c], handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WVZK-gl7cflX","colab_type":"text"},"cell_type":"markdown","source":["### Now we start the flow of training."]},{"metadata":{"id":"41p-1tVGovV1","colab_type":"code","outputId":"30945381-07f1-4aed-d4dd-c61f3051371b","executionInfo":{"status":"ok","timestamp":1553255403835,"user_tz":240,"elapsed":94550,"user":{"displayName":"Yue Wang","photoUrl":"","userId":"12597940806287112734"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["reader = JobReader(token_indexers={\"tokens\": SingleIdTokenIndexer(lowercase_tokens=True),\n","                                   \"token_characters\": TokenCharactersIndexer()})\n","\n","train_dataset = reader.read('/content/gdrive/My Drive/2.1_train.pkl')\n","dev_dataset = reader.read('/content/gdrive/My Drive/2.1_dev.pkl')\n","\n","vocab = Vocabulary.from_instances(train_dataset+dev_dataset, min_count={'tokens': 3})"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/allennlp/data/token_indexers/token_characters_indexer.py:51: UserWarning: You are using the default value (0) of `min_padding_length`, which can cause some subtle bugs (more info see https://github.com/allenai/allennlp/issues/1954). Strongly recommend to set a value, usually the maximum size of the convolutional layer size when using CnnEncoder.\n","  UserWarning)\n","10406it [00:15, 660.72it/s]\n","2974it [00:04, 726.94it/s] \n","100%|██████████| 13380/13380 [01:14<00:00, 180.44it/s]\n"],"name":"stderr"}]},{"metadata":{"id":"MyrAMaLHxJt7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"b66fc59d-09c7-4d78-a0c1-595ef0cc9c59","executionInfo":{"status":"ok","timestamp":1553270383321,"user_tz":240,"elapsed":6243,"user":{"displayName":"Yue Wang","photoUrl":"","userId":"12597940806287112734"}}},"cell_type":"code","source":["reader = JobReader(token_indexers={\"tokens\": SingleIdTokenIndexer(lowercase_tokens=True),\n","                                   \"token_characters\": TokenCharactersIndexer()})\n","\n","test_dataset = reader.read('/content/gdrive/My Drive/tmp/2.1_test.pkl')\n","\n","vocab = Vocabulary.from_files(\"/content/gdrive/My Drive/tmp/vocabulary\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/allennlp/data/token_indexers/token_characters_indexer.py:51: UserWarning: You are using the default value (0) of `min_padding_length`, which can cause some subtle bugs (more info see https://github.com/allenai/allennlp/issues/1954). Strongly recommend to set a value, usually the maximum size of the convolutional layer size when using CnnEncoder.\n","  UserWarning)\n","1487it [00:03, 427.63it/s]\n"],"name":"stderr"}]},{"metadata":{"id":"zXAipVMjrhTy","colab_type":"code","colab":{}},"cell_type":"code","source":["token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n","                           embedding_dim=50,\n","                           pretrained_file=\"https://s3-us-west-2.amazonaws.com/allennlp/datasets/glove/glove.6B.50d.txt.gz\")\n","\n","temp1 = Embedding(num_embeddings=vocab.get_vocab_size('token_characters'),\n","                  embedding_dim=10)\n","temp2 = PytorchSeq2VecWrapper(torch.nn.GRU(10, 25, 2, batch_first=True, \n","                                           dropout=0, bidirectional=False))\n","\n","character_encoding = TokenCharactersEncoder(embedding=temp1, encoder=temp2)\n","word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding,\n","                                          \"token_characters\": character_encoding})\n","lstm = PytorchSeq2VecWrapper(torch.nn.LSTM(75, 40, 2, batch_first=True, \n","                                           dropout=0.25, bidirectional=True))\n","model = LstmClassifier(word_embeddings, lstm, vocab)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BIlMUPGWGzjd","colab_type":"code","colab":{}},"cell_type":"code","source":["with open(\"/content/gdrive/My Drive/tmp/model.th\", 'rb') as f:\n","    model.load_state_dict(torch.load(f))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NNDnjhN_TDTS","colab_type":"code","colab":{}},"cell_type":"code","source":["optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n","\n","iterator = BasicIterator(batch_size=32)\n","iterator.index_with(vocab)\n","\n","model = model.cuda(0)\n","trainer = Trainer(model=model,\n","                  optimizer=optimizer,\n","                  iterator=iterator,\n","                  train_dataset=train_dataset,\n","                  validation_dataset=dev_dataset,\n","                  patience=10,\n","                  num_epochs=20,\n","                  cuda_device=0)\n","\n","trainer.train()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W-zSIQc4tBiq","colab_type":"code","colab":{}},"cell_type":"code","source":["with open(\"/content/gdrive/My Drive/model.th\", 'wb') as f:\n","    torch.save(model.state_dict(), f)\n","vocab.save_to_files(\"/content/gdrive/My Drive/vocabulary\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3L86XNgI6Ln1","colab_type":"text"},"cell_type":"markdown","source":["### Here we start to predict for test dataset."]},{"metadata":{"id":"-4gl1auToSVE","colab_type":"code","outputId":"84ed2cfb-e22f-4934-852f-ef6741cd529b","executionInfo":{"status":"ok","timestamp":1553270718298,"user_tz":240,"elapsed":225123,"user":{"displayName":"Yue Wang","photoUrl":"","userId":"12597940806287112734"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["import numpy as np\n","pred_label = []\n","predictor = Predictor(model, dataset_reader=reader)\n","for i in range(len(test_dataset)):\n","    if i % 1000==0:\n","        print(i)\n","    try:\n","        pred = predictor.predict_instance(test_dataset[i])\n","        pred_label.append(np.argmax(pred['logits']))\n","    except KeyError:\n","        print(i)\n","        pred_label.append(0)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["0\n","865\n","1000\n"],"name":"stdout"}]},{"metadata":{"id":"G7bMGos22636","colab_type":"code","colab":{}},"cell_type":"code","source":["pred_salary = [vocab.get_token_from_index(i, 'labels') for i in pred_label]\n","true_salary = [each['label'].label for each in test_dataset]\n","np.mean(np.array(pred_salary)==np.array(true_salary))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"w3ok8XYhK5Bc","colab_type":"text"},"cell_type":"markdown","source":["### Try things out:"]},{"metadata":{"id":"NxBKx0keR0Q5","colab_type":"code","colab":{}},"cell_type":"code","source":["import csv\n","with open('pred.csv', mode='w') as f:\n","    w = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","    w.writerow(['pred', 'true'])\n","    for i in range(len(pred_salary)):\n","        w.writerow([pred_salary[i], true_salary[i]])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XknDqpSrxdXm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"3b911d0a-a125-4abb-e94c-dae3ef7d9f88","executionInfo":{"status":"ok","timestamp":1553268779009,"user_tz":240,"elapsed":4060,"user":{"displayName":"Yue Wang","photoUrl":"","userId":"12597940806287112734"}}},"cell_type":"code","source":["test_dataset = reader.read('/content/gdrive/My Drive/tmp/2.1_test.pkl')"],"execution_count":54,"outputs":[{"output_type":"stream","text":["1487it [00:01, 917.24it/s]\n"],"name":"stderr"}]},{"metadata":{"id":"bwJ40DQI_V4o","colab_type":"code","colab":{}},"cell_type":"code","source":["with open('/content/gdrive/My Drive/tmp/2.1_test.pkl', 'rb') as f:\n","    d = pickle.load(f)\n","true_salary = [str(each['salary_range']) for each in d]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Cj9cJuTVAyP7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"48495f65-7839-4fb6-ca9f-82f07a186c6b","executionInfo":{"status":"ok","timestamp":1553272603490,"user_tz":240,"elapsed":1319,"user":{"displayName":"Yue Wang","photoUrl":"","userId":"12597940806287112734"}}},"cell_type":"code","source":["\n","evaluations(np.array(true_salary), np.array(pred_salary))"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Normalized confusion matrix\n","[[0.12 0.44 0.24 0.   0.08 0.04 0.04 0.04 0.   0.   0.   0.   0.  ]\n"," [0.03 0.21 0.28 0.17 0.14 0.1  0.   0.07 0.   0.   0.   0.   0.  ]\n"," [0.02 0.1  0.18 0.2  0.22 0.16 0.1  0.   0.   0.   0.02 0.   0.  ]\n"," [0.   0.07 0.18 0.21 0.17 0.17 0.09 0.09 0.   0.02 0.   0.   0.  ]\n"," [0.   0.03 0.03 0.08 0.22 0.28 0.21 0.09 0.03 0.03 0.01 0.   0.  ]\n"," [0.   0.   0.01 0.04 0.15 0.25 0.24 0.11 0.12 0.05 0.01 0.   0.01]\n"," [0.   0.   0.   0.01 0.08 0.15 0.27 0.22 0.15 0.09 0.02 0.   0.  ]\n"," [0.   0.   0.01 0.   0.07 0.13 0.22 0.22 0.21 0.1  0.03 0.   0.  ]\n"," [0.   0.   0.   0.   0.03 0.05 0.11 0.22 0.33 0.17 0.07 0.   0.  ]\n"," [0.   0.   0.   0.01 0.02 0.04 0.09 0.13 0.35 0.27 0.07 0.01 0.01]\n"," [0.   0.   0.   0.   0.02 0.02 0.05 0.14 0.24 0.29 0.23 0.02 0.02]\n"," [0.   0.   0.   0.   0.   0.   0.04 0.08 0.27 0.19 0.23 0.04 0.15]\n"," [0.   0.   0.   0.   0.   0.   0.   0.08 0.17 0.5  0.08 0.   0.17]]\n","Precision 0.41\n","Recall 0.38\n","F1 Score 0.40\n","RMSE 18.62\n"],"name":"stdout"}]},{"metadata":{"id":"Stqe59vcGB9E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"249f063e-80e1-4af8-c64e-2a62de37d1bd","executionInfo":{"status":"ok","timestamp":1553269827210,"user_tz":240,"elapsed":484,"user":{"displayName":"Yue Wang","photoUrl":"","userId":"12597940806287112734"}}},"cell_type":"code","source":["vocab.get_token_from_index(5, 'labels')"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'95.0'"]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"id":"8_GOfO8KQfXk","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import itertools\n","\n","#Evaluation of Model - Confusion Matrix Plot\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.tight_layout()\n","\n","\n","# # Compute confusion matrix\n","# cnf_matrix = confusion_matrix(y_test, y_pred)\n","# np.set_printoptions(precision=2)\n","\n","# # Plot non-normalized confusion matrix\n","# plt.figure()\n","# plot_confusion_matrix(cnf_matrix, classes=['Forged','Authorized'],\n","#                       title='Confusion matrix, without normalization')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aqAJsifjQgEf","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix\n","\n","def evaluations(y_test, y_pred):\n","\n","    # Change type to floats\n","    y_pred = y_pred.astype('float')\n","    y_test = y_test.astype('float')\n","\n","    ### Evaluating the Model using the Testing Dataset\n","    # Plot normalized confusion matrix\n","    labels = ['50-60', '60-70', '70-80', '80-90', '90-100', '100-110', '110-120', '120-130', '130-140', '140-150', '150-160', '160-170', '170+']\n","\n","    # Compute confusion matrix\n","    cnf_matrix = confusion_matrix(y_test, y_pred)\n","    np.set_printoptions(precision=2)\n","\n","    # Plot normalized confusion matrix\n","    # Plot normalized confusion matrix\n","    fig, ax = plt.subplots( nrows=1, ncols=1 , figsize=(8, 8)) \n","    plot_confusion_matrix(cnf_matrix, normalize = True, classes=labels, title='Normalized Confusion Matrix')\n","    fig.savefig('norm_conf_matrix.png')\n","    plt.close(fig)\n","    \n","    # extracting true positives, false negatives, and false positives\n","    cm = confusion_matrix(y_test, y_pred)\n","    cm = np.asmatrix(cm)\n","    tp = np.trace(cm)\n","    fn = np.triu(cm).sum()-np.trace(cm)\n","    fp = np.tril(cm).sum()-np.trace(cm)\n","\n","    # Precision (if we want to minimize false positives)\n","    precision = tp / (tp + fp)\n","    print(\"Precision {:0.2f}\".format(precision))\n","\n","    # Recall (least false negatives)\n","    recall = tp / (tp + fn)\n","    print(\"Recall {:0.2f}\".format(recall))\n","\n","    # F1 Score\n","    # Harmonic mean of PR, used to indicate a balance between \n","    # PR providing each equal weightage, it ranges from 0 to 1. \n","    # F1 Score reaches its best value at 1 (perfect PR) and worst at 0.\n","    # Relations between data’s positive labels and those given by a classifier based on sums of per-text decisions\n","    f1 = (2*precision*recall)/(precision + recall)\n","    print(\"F1 Score {:0.2f}\".format(f1))\n","\n","    ### Calculate RSME\n","    from sklearn.metrics import mean_squared_error\n","    from math import sqrt\n","    rmse = sqrt(mean_squared_error(y_test.astype(np.float), y_pred.astype(np.float)))\n","    print(\"RMSE {:0.2f}\".format(rmse))\n","\n","# ------------------------------------------\n","# Plot a Confusion Matrix \n","# from sklearn.metrics import confusion_matrix\n","# import seaborn as sn\n","# cm = confusion_matrix(y_val,y_pred)\n","# cm_df = pd.DataFrame(cm)\n","# plt.figure(figsize = (10,7))\n","# sn.heatmap(cm_df, annot=True)"],"execution_count":0,"outputs":[]}]}